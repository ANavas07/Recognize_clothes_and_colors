{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importaciones\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#Inicializar utilidad de dibujo para graficar lineas\n",
    "mp_drawing= mp.solutions.drawing_utils\n",
    "#Inicializa el modulo de estimacion de pose (rastrea los puntos)\n",
    "mp_pose=mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo en D:\\IAProyectos\\ProyectoFinal_IA\\models\\mnist_model_mejorado.h5 existe.\n",
      "Modelo cargado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "#Cargar el modelo de entrenamiento\n",
    "# Verificación de la ruta del modelo\n",
    "# model_path = r'D:\\IAProyectos\\ProyectoFinal_IA\\models\\mnist_model.h5'\n",
    "model_path = r'D:\\IAProyectos\\ProyectoFinal_IA\\models\\mnist_model_mejorado.h5'\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"El modelo en {model_path} no existe.\")\n",
    "else:\n",
    "    print(f\"El modelo en {model_path} existe.\")\n",
    "\n",
    "try:\n",
    "    # Cargar el modelo de entrenamiento\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(\"Modelo cargado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el modelo: {e}\")\n",
    "\n",
    "# Mapear índices a nombres de clase\n",
    "# label_to_index = {'Camiseta': 0,'Pantalón': 1,'Suéter': 2,'Vestido': 3,'Suéter': 4,'Zapatilla': 5,\n",
    "#                     'Camiseta': 6,'Zapatilla': 7,'Camiseta': 8,'Zapatilla': 9}\n",
    "\n",
    "label_to_index = {'Camiseta': 0,'Pantalón': 1,'Suéter': 2,'Vestido': 3,'Abrigo': 4,'Sandalia': 5,'Camisa': 6,\n",
    "                    'Zapatilla': 7,'Bolso': 8,'Bota': 9}\n",
    "\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Puntos de interes</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Definir rangos de color HSV y establecer los puntos de interes a analizar</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rangos de colores en HSV\n",
    "\"\"\"\n",
    "Primer par: (0, 50, 50) a (10, 255, 255)\n",
    "    -Hue: 0 a 10 (Los tonos de rojo al principio del espectro)\n",
    "    -Saturation: 50 a 255 (De un rojo ligeramente apagado a un rojo muy saturado)\n",
    "    -Value: 50 a 255 (De un rojo oscuro a un rojo muy brillante)\n",
    "\"\"\"\n",
    "color_ranges = {\n",
    "    \"Rojo\": [(0, 50, 50), (10, 255, 255), (170, 50, 50), (180, 255, 255)],\n",
    "    \"Naranja\": [(11, 50, 50), (25, 255, 255)],\n",
    "    \"Amarillo\": [(26, 50, 50), (35, 255, 255)],\n",
    "    \"Verde Claro\": [(36, 50, 50), (70, 255, 255)],\n",
    "    \"Verde Oscuro\": [(71, 50, 50), (85, 255, 255)],\n",
    "    \"Cian\": [(86, 50, 50), (95, 255, 255)], #Un azul medio claro\n",
    "    \"Azul Claro\": [(96, 50, 50), (110, 255, 255)],\n",
    "    \"Azul Oscuro\": [(111, 50, 50), (125, 255, 255)],\n",
    "    \"Violeta Claro\": [(126, 50, 50), (145, 255, 255)],\n",
    "    \"Violeta Oscuro\": [(146, 50, 50), (160, 255, 255)],\n",
    "    \"Rosa\": [(161, 50, 50), (169, 255, 255)],\n",
    "    \"Marrón Claro\": [(10, 100, 20), (20, 255, 200)],\n",
    "    \"Marrón Oscuro\": [(10, 100, 20), (20, 255, 150)],\n",
    "    \"Blanco\": [(0, 0, 200), (180, 20, 255)],\n",
    "    \"Gris Claro\": [(0, 0, 150), (180, 50, 200)],\n",
    "    \"Gris Oscuro\": [(0, 0, 50), (180, 50, 150)],\n",
    "    \"Negro\": [(0, 0, 0), (180, 255, 50)],\n",
    "    \"Beige\": [(20, 20, 70), (35, 255, 255)],\n",
    "    \"Oro\": [(20, 100, 100), (30, 255, 255)],\n",
    "    \"Plata\": [(0, 0, 180), (180, 20, 255)],\n",
    "    \"Lima\": [(75, 100, 100), (85, 255, 255)],\n",
    "    \"Turquesa\": [(85, 150, 100), (95, 255, 255)], # entre cian y azul claro.\n",
    "    \"Lavanda\": [(120, 50, 100), (140, 255, 255)], #violeta claro.\n",
    "    \"Coral\": [(0, 50, 100), (15, 255, 255)], #entre rosa y naranja\n",
    "    \"Menta\": [(50, 100, 100), (70, 255, 255)],\n",
    "    \"Durazno\": [(10, 50, 100), (20, 255, 255)]\n",
    "}\n",
    "\n",
    "\n",
    "# Lista de puntos de interés / funciona correctamente\n",
    "puntos_interes = [11, 12, 13, 14, 23, 24, 25, 26, 27, 28, 30, 32, 29, 31]\n",
    "\n",
    "# Conexiones relevantes\n",
    "conexiones_interes = [\n",
    "    (11, 12), (12, 14), (11, 13), (24, 23), (24, 26), (23, 25),\n",
    "    (12, 24), (11, 23), (24, 23), (26, 28), (25, 27), (32, 30), \n",
    "    (30, 32), (27, 29)\n",
    "]\n",
    "\n",
    "# Lista de puntos por zonas\n",
    "tronco_superior = [11, 12, 13, 14, 23, 24]\n",
    "tronco_inferior = [23, 24, 25, 26, 27, 28]\n",
    "pies = [28, 32, 30, 27, 29, 31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Funciones</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_nombre_color(hsv_color):\n",
    "    h, s, v = hsv_color\n",
    "    for color, ranges in color_ranges.items():\n",
    "        for i in range(0, len(ranges), 2):\n",
    "            if ranges[i][0] <= h <= ranges[i+1][0] and ranges[i][1] <= s <= ranges[i+1][1] and ranges[i][2] <= v <= ranges[i+1][2]:\n",
    "                return color\n",
    "    return \"Desconocido\"\n",
    "\n",
    "# Función para dibujar las bounding boxes\n",
    "def dibujar_bounding_box(image, puntos):\n",
    "    x_coords = [punto.x for punto in puntos]\n",
    "    y_coords = [punto.y for punto in puntos]\n",
    "    x_min = int(min(x_coords) * image.shape[1])\n",
    "    x_max = int(max(x_coords) * image.shape[1])\n",
    "    y_min = int(min(y_coords) * image.shape[0])\n",
    "    y_max = int(max(y_coords) * image.shape[0])\n",
    "    cv.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "def dibujar_bounding_box_resize(image, landmarks, expand_factor=0.2):\n",
    "    x_coords = [int(landmark.x * image.shape[1]) for landmark in landmarks]\n",
    "    y_coords = [int(landmark.y * image.shape[0]) for landmark in landmarks]\n",
    "    x1, x2 = min(x_coords), max(x_coords)\n",
    "    y1, y2 = min(y_coords), max(y_coords)\n",
    "\n",
    "    # Expandir la bounding box horizontalmente\n",
    "    width = x2 - x1\n",
    "    expand_width = int(width * expand_factor)\n",
    "    x1 = max(0, x1 - expand_width)\n",
    "    x2 = min(image.shape[1], x2 + expand_width)\n",
    "\n",
    "    cv.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "# Función para obtener el color dominante en HSV con suavizado\n",
    "def obtener_color_dominante(image, bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    patch = image[y_min:y_max, x_min:x_max]\n",
    "    if patch.size == 0:\n",
    "        return (0, 0, 0)  # Devolver negro si el parche es inválido\n",
    "\n",
    "    # Aplicar filtro de mediana\n",
    "    patch = cv.medianBlur(patch, 5)\n",
    "    hsv_patch = cv.cvtColor(patch, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Usar k-means para encontrar el color dominante\n",
    "    pixels = hsv_patch.reshape(-1, 3)\n",
    "    k = 3\n",
    "    _, labels, centers = cv.kmeans(pixels.astype(np.float32), k, None,\n",
    "                                (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0), 10, cv.KMEANS_RANDOM_CENTERS)\n",
    "    dominant_color = centers[np.argmax(np.bincount(labels.flatten()))]\n",
    "    return tuple(map(int, dominant_color))\n",
    "\n",
    "\n",
    "def ajustar_brillo(image, factor=1.2):\n",
    "    \"\"\"Aumenta el brillo de la imagen.\"\"\"\n",
    "    hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "    hsv = np.array(hsv, dtype=np.float64)\n",
    "    hsv[:, :, 2] = hsv[:, :, 2] * factor\n",
    "    hsv[:, :, 2][hsv[:, :, 2] > 255] = 255\n",
    "    hsv = np.array(hsv, dtype=np.uint8)\n",
    "    bright_img = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "    return bright_img\n",
    "\n",
    "\n",
    "# Función para predecir el tipo de prenda\n",
    "def predecir_prenda(image, bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    roi = image[y1:y2, x1:x2]\n",
    "    if roi.size == 0:\n",
    "        return None\n",
    "    roi = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "    roi = cv.resize(roi, (28, 28))\n",
    "    roi = roi / 255.0\n",
    "    roi = roi.reshape(1, 28, 28, 1)\n",
    "    prediction = model.predict(roi)\n",
    "    return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Captura de video y procesamiento del algoritmo</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# Inicialización de Mediapipe y OpenCV\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Ajustar el brillo de la imagen\n",
    "        frame = ajustar_brillo(frame, factor=1.2)\n",
    "        image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        resultados = pose.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "\n",
    "        if resultados.pose_landmarks:\n",
    "            puntos_de_referencia = resultados.pose_landmarks.landmark\n",
    "            puntos_hito = [puntos_de_referencia[i] for i in puntos_interes]\n",
    "\n",
    "            for idx, puntos_ref in zip(puntos_interes, puntos_hito):\n",
    "                x = int(puntos_ref.x * image.shape[1])\n",
    "                y = int(puntos_ref.y * image.shape[0])\n",
    "                cv.circle(image, (x, y), 5, (245, 117, 66), -1)\n",
    "\n",
    "            for start_idx, end_idx in conexiones_interes:\n",
    "                if start_idx in puntos_interes and end_idx in puntos_interes:\n",
    "                    start_point = (int(puntos_de_referencia[start_idx].x * image.shape[1]),\n",
    "                                   int(puntos_de_referencia[start_idx].y * image.shape[0]))\n",
    "                    end_point = (int(puntos_de_referencia[end_idx].x * image.shape[1]),\n",
    "                                 int(puntos_de_referencia[end_idx].y * image.shape[0]))\n",
    "                    cv.line(image, start_point, end_point, (245, 66, 230), 2)\n",
    "\n",
    "            bbox_tronco_superior = dibujar_bounding_box(image, [puntos_de_referencia[i] for i in tronco_superior])\n",
    "            bbox_tronco_inferior = dibujar_bounding_box_resize(image, [puntos_de_referencia[i] for i in tronco_inferior])\n",
    "            bbox_pies = dibujar_bounding_box(image, [puntos_de_referencia[i] for i in pies])\n",
    "\n",
    "            pred_tronco_superior = predecir_prenda(image, bbox_tronco_superior)\n",
    "            pred_tronco_inferior = predecir_prenda(image, bbox_tronco_inferior)\n",
    "            pred_pies = predecir_prenda(image, bbox_pies)\n",
    "            if pred_tronco_superior or pred_tronco_inferior or pred_pies is not None:\n",
    "                label_tronco_superior = index_to_label.get(pred_tronco_superior, \"Camiseta\")\n",
    "                label_tronco_inferior = index_to_label.get(pred_tronco_superior, \"Pantalon\")\n",
    "                label_pies = index_to_label.get(pred_tronco_superior, \"Zapatilla\")\n",
    "                cv.putText(image, label_tronco_superior, (bbox_tronco_superior[0], bbox_tronco_superior[1] - 30), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                cv.putText(image, label_tronco_inferior, (bbox_tronco_inferior[0], bbox_tronco_inferior[1] - 30), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                cv.putText(image, label_pies, (bbox_pies[0], bbox_pies[1] - 30), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "            \n",
    "            \n",
    "            color_intermedio_tronco_superior = obtener_color_dominante(image, bbox_tronco_superior)\n",
    "            color_tronco_inferior = obtener_color_dominante(image, bbox_tronco_inferior)\n",
    "            color_pies = obtener_color_dominante(image, bbox_pies)\n",
    "\n",
    "            nombre_color_tronco_superior = obtener_nombre_color(color_intermedio_tronco_superior)\n",
    "            nombre_color_tronco_inferior = obtener_nombre_color(color_tronco_inferior)\n",
    "            nombre_color_pies = obtener_nombre_color(color_pies)\n",
    "\n",
    "            cv.putText(image, nombre_color_tronco_superior, (bbox_tronco_superior[0], bbox_tronco_superior[1] - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv.putText(image, nombre_color_tronco_inferior, (bbox_tronco_inferior[0], bbox_tronco_inferior[1] - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            cv.putText(image, nombre_color_pies, (bbox_pies[0], bbox_pies[1] - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv.imshow('Ventana de captura', image)\n",
    "\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
